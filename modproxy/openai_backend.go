package modproxy

import (
	"bufio"
	"bytes"
	"encoding/json"
	"fmt"
	"github.com/gin-gonic/gin"
	"io"
	"log"
	"modhub/common"
	"net/http"
	"strings"
	"time"
)

type OpenAIStreamResponse struct {
	ID                string `json:"id"`
	Object            string `json:"object"`
	Created           int64  `json:"created"`
	Model             string `json:"model"`
	SystemFingerprint string `json:"system_fingerprint,omitempty"` // å¯é€‰å­—æ®µ
	Choices           []struct {
		Index int `json:"index"`
		Delta struct {
			Content string `json:"content"`
			// å¦‚æœæœ‰å…¶ä»– delta å­—æ®µï¼ˆå¦‚ role, function_call ç­‰ï¼‰ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
		} `json:"delta"`
		Logprobs     interface{} `json:"logprobs"`      // å¯èƒ½æ˜¯ null æˆ–å¤æ‚ç»“æ„
		FinishReason string      `json:"finish_reason"` // å¯èƒ½æ˜¯ null æˆ– "stop"/"length"/"function_call" ç­‰
	} `json:"choices"`
	Usage *struct { // å¯é€‰å­—æ®µï¼ˆæµå¼å“åº”ä¸­é€šå¸¸ä¸º nullï¼‰
		PromptTokens     int `json:"prompt_tokens"`
		CompletionTokens int `json:"completion_tokens"`
		TotalTokens      int `json:"total_tokens"`
	} `json:"usage,omitempty"`
}

func ForwardToOpenAIStream(openaiURL string, apiKey string, req common.ChatRequest, c *gin.Context) error {
	// å°†è¯·æ±‚å¯¹è±¡åºåˆ—åŒ–ä¸º JSON
	reqBody, err := json.Marshal(req)
	if err != nil {
		return err
	}

	// æ„é€  HTTP è¯·æ±‚
	client := &http.Client{}
	httpReq, err := http.NewRequest("POST", openaiURL, bytes.NewBuffer(reqBody))
	if err != nil {
		return err
	}
	httpReq.Header.Set("Content-Type", "application/json")
	httpReq.Header.Set("Authorization", "Bearer "+apiKey) // è®¾ç½® OpenAI çš„ API å¯†é’¥

	// å‘èµ· HTTP è¯·æ±‚
	resp, err := client.Do(httpReq)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	// æ£€æŸ¥åç«¯æœåŠ¡çš„å“åº”çŠ¶æ€
	if resp.StatusCode != http.StatusOK {
		var errorResponse map[string]interface{}
		_ = json.NewDecoder(resp.Body).Decode(&errorResponse) // å°è¯•è§£æé”™è¯¯ä¿¡æ¯
		log.Printf("OpenAI æœåŠ¡å“åº”çŠ¶æ€ç é”™è¯¯: %d, é”™è¯¯ä¿¡æ¯: %v", resp.StatusCode, errorResponse)
		return fmt.Errorf("OpenAI æœåŠ¡å“åº”çŠ¶æ€ç é”™è¯¯: %d", resp.StatusCode)
	}

	// è®¾ç½®å“åº”å¤´ï¼Œæ”¯æŒæµå¼ä¼ è¾“
	c.Header("Content-Type", resp.Header.Get("Content-Type")) // ç»§æ‰¿åç«¯æœåŠ¡å“åº”çš„å†…å®¹ç±»å‹ï¼Œé€šå¸¸æ˜¯ "application/json"
	c.Header("Transfer-Encoding", "chunked")
	c.Status(http.StatusOK)

	// ä½¿ç”¨æµå¼å¤„ç†é€å—è¯»å–å“åº”ä½“å¹¶å¤„ç†
	reader := bufio.NewReader(resp.Body)

	isStream := true
	if req.Stream != nil && !*req.Stream {
		isStream = false
	}
	var sb strings.Builder

	for {
		// æ¯æ¬¡è¯»å–ä¸€ä¸ªæ•°æ®å—
		chunk, err := reader.ReadBytes('\n') // OpenAI çš„æµå¼ API é€šå¸¸ä»¥æ¢è¡Œç¬¦åˆ†å‰²
		if len(chunk) > 0 {
			processedChunk := ConvertToOllama(string(chunk), req.Model, &sb)
			if len(processedChunk) == 0 {
				continue
			}
			if isStream {
				// å°†å¤„ç†åçš„æ•°æ®å†™å…¥å®¢æˆ·ç«¯å“åº”
				if _, writeErr := c.Writer.Write([]byte(processedChunk)); writeErr != nil {
					log.Println("å†™å…¥å®¢æˆ·ç«¯å“åº”æ—¶å‡ºé”™:", writeErr)
					c.JSON(http.StatusInternalServerError, gin.H{"error": "å†™å…¥å®¢æˆ·ç«¯å“åº”æ—¶å‡ºé”™"})
					return writeErr
				}

				// åˆ·æ–°ç¼“å†²åŒºï¼Œä¿è¯å®¢æˆ·ç«¯å®æ—¶æ¥æ”¶åˆ°æ•°æ®
				c.Writer.Flush()
			} else {
				// éæµå¼æ¨¡å¼ä¸‹ï¼Œç´¯ç§¯æ•°æ®åˆ°ç¼“å†²åŒº
				sb.Write([]byte(processedChunk))
			}
		}

		// æ£€æŸ¥æ˜¯å¦é‡åˆ° EOF æˆ–å…¶ä»–é”™è¯¯
		if err != nil {
			if err == io.EOF {
				break
			}
			log.Println("è¯»å–å“åº”æ•°æ®æ—¶å‡ºé”™:", err)
			c.JSON(http.StatusInternalServerError, gin.H{"error": "è¯»å–å“åº”æ•°æ®æ—¶å‡ºé”™"})
			return err
		}
	}

	if !isStream {
		// éæµå¼æ¨¡å¼ä¸‹ï¼Œç»„è£…å®Œæ•´çš„å“åº”
		output := common.OutputData{
			Model:     req.Model,
			CreatedAt: time.Now().Format(time.RFC3339Nano), // å½“å‰æ—¶é—´
			Message: common.Message{
				Role:    "assistant",
				Content: sb.String(),
			},
			Done: true, // å‡è®¾å“åº”æ˜¯å®Œæ•´çš„ï¼Œç›´æ¥æ ‡è®° done ä¸º true
		}
		c.Header("Content-Type", "application/json")
		c.JSON(http.StatusOK, output)
	}

	return nil
}

//	func ConvertToOllama(input string, model string, sb *strings.Builder) (result string) {
//		defer func() {
//			if r := recover(); r != nil {
//				result = ""
//			}
//		}()
//		// è§£æè¾“å…¥æ•°æ®
//		cleaned := strings.Trim(strings.TrimPrefix(input, "data:"), "\n")
//		log.Println(cleaned)
//
//		if len(cleaned) == 0 {
//			return ""
//		}
//
//		var inputData map[string]interface{}
//		err := json.Unmarshal([]byte(cleaned), &inputData)
//		if err != nil {
//			return ""
//		}
//		//delete inputData["choices"][0]["delta"]["role"]
//
//		return cleaned
//	}
//
// ConvertToOllama converts OpenAI streaming response chunk to Ollama format
// Parameters:
// - chunk: Raw JSON string from OpenAI stream
// - model: Model name to include in response
// - sb: Optional string builder for accumulating context (used for non-streaming mode)
// Returns:
// - Processed JSON string in Ollama format
// - Empty string if chunk should be skipped
func ConvertToOllama(chunk string, model string, sb *strings.Builder) string {
	// Handle OpenAI's [DONE] event
	chunk = strings.Trim(strings.TrimPrefix(chunk, "data:"), "\n")
	var output common.OutputData

	if len(chunk) == 0 {
		return ""
	}

	if chunk == "[DONE]" {
		// åˆ›å»ºè¾“å‡ºæ•°æ®
		output = common.OutputData{
			Model:     model,
			CreatedAt: time.Now().Format(time.RFC3339Nano), // å½“å‰æ—¶é—´
			Message: common.Message{
				Role:    "assistant",
				Content: "",
			},
			Done: true, // å‡è®¾ Answer æ˜¯å®Œæ•´çš„ï¼Œç›´æ¥æ ‡è®° done ä¸º true
		}
	} else {
		var inputData OpenAIStreamResponse
		err := json.Unmarshal([]byte(chunk), &inputData)
		if err != nil {
			return ""
		}
		if len(inputData.Choices) == 0 {
			return ""
		}

		output = common.OutputData{
			Model:     model,
			CreatedAt: time.Now().Format(time.RFC3339Nano), // å½“å‰æ—¶é—´
			Message: common.Message{
				Role:    "assistant",
				Content: inputData.Choices[0].Delta.Content,
			},
			Done: true, // å‡è®¾ Answer æ˜¯å®Œæ•´çš„ï¼Œç›´æ¥æ ‡è®° done ä¸º true
		}
	}

	var buffer bytes.Buffer
	encoder := json.NewEncoder(&buffer)
	encoder.SetEscapeHTML(false) // ç¦ç”¨ HTML è½¬ä¹‰
	err := encoder.Encode(output)
	if err != nil {
		log.Println("Error encoding JSON:", err)
		return ""
	}
	return string(buffer.String())
}

/*
{
    "id": "chatcmpl-140",
    "object": "chat.completion.chunk",
    "created": 1745906094,
    "model": "deepseek-v3:671b(sdu)",
    "system_fingerprint": "fp_ollama",
    "choices": [
        {
            "index": 0,
            "delta": {
                "role": "assistant",
                "content": " ğŸ˜Š"
            },
            "finish_reason": null
        }
    ]
}

{
    "id": "chatcmpl-BRY8hW9BP3CkzRqqJbMmyzmnHRSR8",
    "object": "chat.completion.chunk",
    "created": 1745905787,
    "model": "gpt-4o-2024-11-20",
    "system_fingerprint": "fp_ee1d74bde0",
    "choices": [
        {
            "index": 0,
            "delta": {
                "content": "http"
            },
            "logprobs": null,
            "finish_reason": null
        }
    ],
    "usage": null
}

{
    "id": "chatcmpl-BRY8hW9BP3CkzRqqJbMmyzmnHRSR8",
    "object": "chat.completion.chunk",
    "created": 1745905787,
    "model": "gpt-4o-2024-11-20",
    "system_fingerprint": "fp_ee1d74bde0",
    "choices": [
        {
            "index": 0,
            "delta": {
                "content": "domain"
            },
            "logprobs": null,
            "finish_reason": null
        }
    ],
    "usage": null
}
*/
